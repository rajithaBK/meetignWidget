{"ast":null,"code":"\"use strict\";\n\nvar _regeneratorRuntime = require(\"C:\\\\Users\\\\rkanthet\\\\Documents\\\\test_window_object\\\\node_modules\\\\@babel\\\\runtime\\\\regenerator\\\\index.js\");\n\nvar _asyncToGenerator = require(\"C:/Users/rkanthet/Documents/test_window_object/node_modules/@babel/runtime/helpers/asyncToGenerator.js\").default;\n\nvar _classCallCheck = require(\"C:/Users/rkanthet/Documents/test_window_object/node_modules/@babel/runtime/helpers/classCallCheck.js\").default;\n\nvar _createClass = require(\"C:/Users/rkanthet/Documents/test_window_object/node_modules/@babel/runtime/helpers/createClass.js\").default;\n\nvar _inherits = require(\"C:/Users/rkanthet/Documents/test_window_object/node_modules/@babel/runtime/helpers/inherits.js\").default;\n\nvar _createSuper = require(\"C:/Users/rkanthet/Documents/test_window_object/node_modules/@babel/runtime/helpers/createSuper.js\").default;\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.fromFile = exports.FileTokenizer = void 0;\n\nvar AbstractTokenizer_1 = require(\"./AbstractTokenizer\");\n\nvar peek_readable_1 = require(\"peek-readable\");\n\nvar fs = require(\"./FsPromise\");\n\nvar FileTokenizer = /*#__PURE__*/function (_AbstractTokenizer_1$) {\n  _inherits(FileTokenizer, _AbstractTokenizer_1$);\n\n  var _super = _createSuper(FileTokenizer);\n\n  function FileTokenizer(fd, fileInfo) {\n    var _this;\n\n    _classCallCheck(this, FileTokenizer);\n\n    _this = _super.call(this, fileInfo);\n    _this.fd = fd;\n    return _this;\n  }\n  /**\r\n   * Read buffer from file\r\n   * @param uint8Array - Uint8Array to write result to\r\n   * @param options - Read behaviour options\r\n   * @returns Promise number of bytes read\r\n   */\n\n\n  _createClass(FileTokenizer, [{\n    key: \"readBuffer\",\n    value: function () {\n      var _readBuffer = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(uint8Array, options) {\n        var normOptions, res;\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                normOptions = this.normalizeOptions(uint8Array, options);\n                this.position = normOptions.position;\n                _context.next = 4;\n                return fs.read(this.fd, uint8Array, normOptions.offset, normOptions.length, normOptions.position);\n\n              case 4:\n                res = _context.sent;\n                this.position += res.bytesRead;\n\n                if (!(res.bytesRead < normOptions.length && (!options || !options.mayBeLess))) {\n                  _context.next = 8;\n                  break;\n                }\n\n                throw new peek_readable_1.EndOfStreamError();\n\n              case 8:\n                return _context.abrupt(\"return\", res.bytesRead);\n\n              case 9:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n\n      function readBuffer(_x, _x2) {\n        return _readBuffer.apply(this, arguments);\n      }\n\n      return readBuffer;\n    }()\n    /**\r\n     * Peek buffer from file\r\n     * @param uint8Array - Uint8Array (or Buffer) to write data to\r\n     * @param options - Read behaviour options\r\n     * @returns Promise number of bytes read\r\n     */\n\n  }, {\n    key: \"peekBuffer\",\n    value: function () {\n      var _peekBuffer = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(uint8Array, options) {\n        var normOptions, res;\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                normOptions = this.normalizeOptions(uint8Array, options);\n                _context2.next = 3;\n                return fs.read(this.fd, uint8Array, normOptions.offset, normOptions.length, normOptions.position);\n\n              case 3:\n                res = _context2.sent;\n\n                if (!(!normOptions.mayBeLess && res.bytesRead < normOptions.length)) {\n                  _context2.next = 6;\n                  break;\n                }\n\n                throw new peek_readable_1.EndOfStreamError();\n\n              case 6:\n                return _context2.abrupt(\"return\", res.bytesRead);\n\n              case 7:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, this);\n      }));\n\n      function peekBuffer(_x3, _x4) {\n        return _peekBuffer.apply(this, arguments);\n      }\n\n      return peekBuffer;\n    }()\n  }, {\n    key: \"close\",\n    value: function () {\n      var _close = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3() {\n        return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n          while (1) {\n            switch (_context3.prev = _context3.next) {\n              case 0:\n                return _context3.abrupt(\"return\", fs.close(this.fd));\n\n              case 1:\n              case \"end\":\n                return _context3.stop();\n            }\n          }\n        }, _callee3, this);\n      }));\n\n      function close() {\n        return _close.apply(this, arguments);\n      }\n\n      return close;\n    }()\n  }]);\n\n  return FileTokenizer;\n}(AbstractTokenizer_1.AbstractTokenizer);\n\nexports.FileTokenizer = FileTokenizer;\n\nfunction fromFile(_x5) {\n  return _fromFile.apply(this, arguments);\n}\n\nfunction _fromFile() {\n  _fromFile = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4(sourceFilePath) {\n    var stat, fd;\n    return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n      while (1) {\n        switch (_context4.prev = _context4.next) {\n          case 0:\n            _context4.next = 2;\n            return fs.stat(sourceFilePath);\n\n          case 2:\n            stat = _context4.sent;\n\n            if (stat.isFile) {\n              _context4.next = 5;\n              break;\n            }\n\n            throw new Error(\"File not a file: \".concat(sourceFilePath));\n\n          case 5:\n            _context4.next = 7;\n            return fs.open(sourceFilePath, 'r');\n\n          case 7:\n            fd = _context4.sent;\n            return _context4.abrupt(\"return\", new FileTokenizer(fd, {\n              path: sourceFilePath,\n              size: stat.size\n            }));\n\n          case 9:\n          case \"end\":\n            return _context4.stop();\n        }\n      }\n    }, _callee4);\n  }));\n  return _fromFile.apply(this, arguments);\n}\n\nexports.fromFile = fromFile;","map":{"version":3,"sources":["C:/Users/rkanthet/Documents/test_window_object/node_modules/strtok3/lib/FileTokenizer.js"],"names":["Object","defineProperty","exports","value","fromFile","FileTokenizer","AbstractTokenizer_1","require","peek_readable_1","fs","fd","fileInfo","uint8Array","options","normOptions","normalizeOptions","position","read","offset","length","res","bytesRead","mayBeLess","EndOfStreamError","close","AbstractTokenizer","sourceFilePath","stat","isFile","Error","open","path","size"],"mappings":"AAAA;;;;;;;;;;;;;;AACAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C;AACAD,OAAO,CAACE,QAAR,GAAmBF,OAAO,CAACG,aAAR,GAAwB,KAAK,CAAhD;;AACA,IAAMC,mBAAmB,GAAGC,OAAO,CAAC,qBAAD,CAAnC;;AACA,IAAMC,eAAe,GAAGD,OAAO,CAAC,eAAD,CAA/B;;AACA,IAAME,EAAE,GAAGF,OAAO,CAAC,aAAD,CAAlB;;IACMF,a;;;;;AACF,yBAAYK,EAAZ,EAAgBC,QAAhB,EAA0B;AAAA;;AAAA;;AACtB,8BAAMA,QAAN;AACA,UAAKD,EAAL,GAAUA,EAAV;AAFsB;AAGzB;AACD;AACJ;AACA;AACA;AACA;AACA;;;;;;iFACI,iBAAiBE,UAAjB,EAA6BC,OAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AACUC,gBAAAA,WADV,GACwB,KAAKC,gBAAL,CAAsBH,UAAtB,EAAkCC,OAAlC,CADxB;AAEI,qBAAKG,QAAL,GAAgBF,WAAW,CAACE,QAA5B;AAFJ;AAAA,uBAGsBP,EAAE,CAACQ,IAAH,CAAQ,KAAKP,EAAb,EAAiBE,UAAjB,EAA6BE,WAAW,CAACI,MAAzC,EAAiDJ,WAAW,CAACK,MAA7D,EAAqEL,WAAW,CAACE,QAAjF,CAHtB;;AAAA;AAGUI,gBAAAA,GAHV;AAII,qBAAKJ,QAAL,IAAiBI,GAAG,CAACC,SAArB;;AAJJ,sBAKQD,GAAG,CAACC,SAAJ,GAAgBP,WAAW,CAACK,MAA5B,KAAuC,CAACN,OAAD,IAAY,CAACA,OAAO,CAACS,SAA5D,CALR;AAAA;AAAA;AAAA;;AAAA,sBAMc,IAAId,eAAe,CAACe,gBAApB,EANd;;AAAA;AAAA,iDAQWH,GAAG,CAACC,SARf;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,O;;;;;;;;AAUA;AACJ;AACA;AACA;AACA;AACA;;;;;iFACI,kBAAiBT,UAAjB,EAA6BC,OAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AACUC,gBAAAA,WADV,GACwB,KAAKC,gBAAL,CAAsBH,UAAtB,EAAkCC,OAAlC,CADxB;AAAA;AAAA,uBAEsBJ,EAAE,CAACQ,IAAH,CAAQ,KAAKP,EAAb,EAAiBE,UAAjB,EAA6BE,WAAW,CAACI,MAAzC,EAAiDJ,WAAW,CAACK,MAA7D,EAAqEL,WAAW,CAACE,QAAjF,CAFtB;;AAAA;AAEUI,gBAAAA,GAFV;;AAAA,sBAGS,CAACN,WAAW,CAACQ,SAAd,IAA4BF,GAAG,CAACC,SAAJ,GAAgBP,WAAW,CAACK,MAHhE;AAAA;AAAA;AAAA;;AAAA,sBAIc,IAAIX,eAAe,CAACe,gBAApB,EAJd;;AAAA;AAAA,kDAMWH,GAAG,CAACC,SANf;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,O;;;;;;;;;;;4EAQA;AAAA;AAAA;AAAA;AAAA;AAAA,kDACWZ,EAAE,CAACe,KAAH,CAAS,KAAKd,EAAd,CADX;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,O;;;;;;;;;;;EAnCwBJ,mBAAmB,CAACmB,iB;;AAuChDvB,OAAO,CAACG,aAAR,GAAwBA,aAAxB;;SACeD,Q;;;;;uEAAf,kBAAwBsB,cAAxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBACuBjB,EAAE,CAACkB,IAAH,CAAQD,cAAR,CADvB;;AAAA;AACUC,YAAAA,IADV;;AAAA,gBAESA,IAAI,CAACC,MAFd;AAAA;AAAA;AAAA;;AAAA,kBAGc,IAAIC,KAAJ,4BAA8BH,cAA9B,EAHd;;AAAA;AAAA;AAAA,mBAKqBjB,EAAE,CAACqB,IAAH,CAAQJ,cAAR,EAAwB,GAAxB,CALrB;;AAAA;AAKUhB,YAAAA,EALV;AAAA,8CAMW,IAAIL,aAAJ,CAAkBK,EAAlB,EAAsB;AAAEqB,cAAAA,IAAI,EAAEL,cAAR;AAAwBM,cAAAA,IAAI,EAAEL,IAAI,CAACK;AAAnC,aAAtB,CANX;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,G;;;;AAQA9B,OAAO,CAACE,QAAR,GAAmBA,QAAnB","sourcesContent":["\"use strict\";\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nexports.fromFile = exports.FileTokenizer = void 0;\r\nconst AbstractTokenizer_1 = require(\"./AbstractTokenizer\");\r\nconst peek_readable_1 = require(\"peek-readable\");\r\nconst fs = require(\"./FsPromise\");\r\nclass FileTokenizer extends AbstractTokenizer_1.AbstractTokenizer {\r\n    constructor(fd, fileInfo) {\r\n        super(fileInfo);\r\n        this.fd = fd;\r\n    }\r\n    /**\r\n     * Read buffer from file\r\n     * @param uint8Array - Uint8Array to write result to\r\n     * @param options - Read behaviour options\r\n     * @returns Promise number of bytes read\r\n     */\r\n    async readBuffer(uint8Array, options) {\r\n        const normOptions = this.normalizeOptions(uint8Array, options);\r\n        this.position = normOptions.position;\r\n        const res = await fs.read(this.fd, uint8Array, normOptions.offset, normOptions.length, normOptions.position);\r\n        this.position += res.bytesRead;\r\n        if (res.bytesRead < normOptions.length && (!options || !options.mayBeLess)) {\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        }\r\n        return res.bytesRead;\r\n    }\r\n    /**\r\n     * Peek buffer from file\r\n     * @param uint8Array - Uint8Array (or Buffer) to write data to\r\n     * @param options - Read behaviour options\r\n     * @returns Promise number of bytes read\r\n     */\r\n    async peekBuffer(uint8Array, options) {\r\n        const normOptions = this.normalizeOptions(uint8Array, options);\r\n        const res = await fs.read(this.fd, uint8Array, normOptions.offset, normOptions.length, normOptions.position);\r\n        if ((!normOptions.mayBeLess) && res.bytesRead < normOptions.length) {\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        }\r\n        return res.bytesRead;\r\n    }\r\n    async close() {\r\n        return fs.close(this.fd);\r\n    }\r\n}\r\nexports.FileTokenizer = FileTokenizer;\r\nasync function fromFile(sourceFilePath) {\r\n    const stat = await fs.stat(sourceFilePath);\r\n    if (!stat.isFile) {\r\n        throw new Error(`File not a file: ${sourceFilePath}`);\r\n    }\r\n    const fd = await fs.open(sourceFilePath, 'r');\r\n    return new FileTokenizer(fd, { path: sourceFilePath, size: stat.size });\r\n}\r\nexports.fromFile = fromFile;\r\n"]},"metadata":{},"sourceType":"script"}