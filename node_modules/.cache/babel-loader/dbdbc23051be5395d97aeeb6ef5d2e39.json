{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.ReadStreamTokenizer = void 0;\n\nconst AbstractTokenizer_1 = require(\"./AbstractTokenizer\");\n\nconst peek_readable_1 = require(\"peek-readable\");\n\nconst maxBufferSize = 256000;\n\nclass ReadStreamTokenizer extends AbstractTokenizer_1.AbstractTokenizer {\n  constructor(stream, fileInfo) {\n    super(fileInfo);\n    this.streamReader = new peek_readable_1.StreamReader(stream);\n  }\n  /**\r\n   * Get file information, an HTTP-client may implement this doing a HEAD request\r\n   * @return Promise with file information\r\n   */\n\n\n  async getFileInfo() {\n    return this.fileInfo;\n  }\n  /**\r\n   * Read buffer from tokenizer\r\n   * @param uint8Array - Target Uint8Array to fill with data read from the tokenizer-stream\r\n   * @param options - Read behaviour options\r\n   * @returns Promise with number of bytes read\r\n   */\n\n\n  async readBuffer(uint8Array, options) {\n    const normOptions = this.normalizeOptions(uint8Array, options);\n    const skipBytes = normOptions.position - this.position;\n\n    if (skipBytes > 0) {\n      await this.ignore(skipBytes);\n      return this.readBuffer(uint8Array, options);\n    } else if (skipBytes < 0) {\n      throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n    }\n\n    if (normOptions.length === 0) {\n      return 0;\n    }\n\n    const bytesRead = await this.streamReader.read(uint8Array, normOptions.offset, normOptions.length);\n    this.position += bytesRead;\n\n    if ((!options || !options.mayBeLess) && bytesRead < normOptions.length) {\n      throw new peek_readable_1.EndOfStreamError();\n    }\n\n    return bytesRead;\n  }\n  /**\r\n   * Peek (read ahead) buffer from tokenizer\r\n   * @param uint8Array - Uint8Array (or Buffer) to write data to\r\n   * @param options - Read behaviour options\r\n   * @returns Promise with number of bytes peeked\r\n   */\n\n\n  async peekBuffer(uint8Array, options) {\n    const normOptions = this.normalizeOptions(uint8Array, options);\n    let bytesRead = 0;\n\n    if (normOptions.position) {\n      const skipBytes = normOptions.position - this.position;\n\n      if (skipBytes > 0) {\n        const skipBuffer = new Uint8Array(normOptions.length + skipBytes);\n        bytesRead = await this.peekBuffer(skipBuffer, {\n          mayBeLess: normOptions.mayBeLess\n        });\n        uint8Array.set(skipBuffer.subarray(skipBytes), normOptions.offset);\n        return bytesRead - skipBytes;\n      } else if (skipBytes < 0) {\n        throw new Error('Cannot peek from a negative offset in a stream');\n      }\n    }\n\n    if (normOptions.length > 0) {\n      try {\n        bytesRead = await this.streamReader.peek(uint8Array, normOptions.offset, normOptions.length);\n      } catch (err) {\n        if (options && options.mayBeLess && err instanceof peek_readable_1.EndOfStreamError) {\n          return 0;\n        }\n\n        throw err;\n      }\n\n      if (!normOptions.mayBeLess && bytesRead < normOptions.length) {\n        throw new peek_readable_1.EndOfStreamError();\n      }\n    }\n\n    return bytesRead;\n  }\n\n  async ignore(length) {\n    // debug(`ignore ${this.position}...${this.position + length - 1}`);\n    const bufSize = Math.min(maxBufferSize, length);\n    const buf = new Uint8Array(bufSize);\n    let totBytesRead = 0;\n\n    while (totBytesRead < length) {\n      const remaining = length - totBytesRead;\n      const bytesRead = await this.readBuffer(buf, {\n        length: Math.min(bufSize, remaining)\n      });\n\n      if (bytesRead < 0) {\n        return bytesRead;\n      }\n\n      totBytesRead += bytesRead;\n    }\n\n    return totBytesRead;\n  }\n\n}\n\nexports.ReadStreamTokenizer = ReadStreamTokenizer;","map":{"version":3,"sources":["C:/Users/rkanthet/Documents/test_window_object/node_modules/strtok3/lib/ReadStreamTokenizer.js"],"names":["Object","defineProperty","exports","value","ReadStreamTokenizer","AbstractTokenizer_1","require","peek_readable_1","maxBufferSize","AbstractTokenizer","constructor","stream","fileInfo","streamReader","StreamReader","getFileInfo","readBuffer","uint8Array","options","normOptions","normalizeOptions","skipBytes","position","ignore","Error","length","bytesRead","read","offset","mayBeLess","EndOfStreamError","peekBuffer","skipBuffer","Uint8Array","set","subarray","peek","err","bufSize","Math","min","buf","totBytesRead","remaining"],"mappings":"AAAA;;AACAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C;AACAD,OAAO,CAACE,mBAAR,GAA8B,KAAK,CAAnC;;AACA,MAAMC,mBAAmB,GAAGC,OAAO,CAAC,qBAAD,CAAnC;;AACA,MAAMC,eAAe,GAAGD,OAAO,CAAC,eAAD,CAA/B;;AACA,MAAME,aAAa,GAAG,MAAtB;;AACA,MAAMJ,mBAAN,SAAkCC,mBAAmB,CAACI,iBAAtD,CAAwE;AACpEC,EAAAA,WAAW,CAACC,MAAD,EAASC,QAAT,EAAmB;AAC1B,UAAMA,QAAN;AACA,SAAKC,YAAL,GAAoB,IAAIN,eAAe,CAACO,YAApB,CAAiCH,MAAjC,CAApB;AACH;AACD;AACJ;AACA;AACA;;;AACqB,QAAXI,WAAW,GAAG;AAChB,WAAO,KAAKH,QAAZ;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;;;AACoB,QAAVI,UAAU,CAACC,UAAD,EAAaC,OAAb,EAAsB;AAClC,UAAMC,WAAW,GAAG,KAAKC,gBAAL,CAAsBH,UAAtB,EAAkCC,OAAlC,CAApB;AACA,UAAMG,SAAS,GAAGF,WAAW,CAACG,QAAZ,GAAuB,KAAKA,QAA9C;;AACA,QAAID,SAAS,GAAG,CAAhB,EAAmB;AACf,YAAM,KAAKE,MAAL,CAAYF,SAAZ,CAAN;AACA,aAAO,KAAKL,UAAL,CAAgBC,UAAhB,EAA4BC,OAA5B,CAAP;AACH,KAHD,MAIK,IAAIG,SAAS,GAAG,CAAhB,EAAmB;AACpB,YAAM,IAAIG,KAAJ,CAAU,uEAAV,CAAN;AACH;;AACD,QAAIL,WAAW,CAACM,MAAZ,KAAuB,CAA3B,EAA8B;AAC1B,aAAO,CAAP;AACH;;AACD,UAAMC,SAAS,GAAG,MAAM,KAAKb,YAAL,CAAkBc,IAAlB,CAAuBV,UAAvB,EAAmCE,WAAW,CAACS,MAA/C,EAAuDT,WAAW,CAACM,MAAnE,CAAxB;AACA,SAAKH,QAAL,IAAiBI,SAAjB;;AACA,QAAI,CAAC,CAACR,OAAD,IAAY,CAACA,OAAO,CAACW,SAAtB,KAAoCH,SAAS,GAAGP,WAAW,CAACM,MAAhE,EAAwE;AACpE,YAAM,IAAIlB,eAAe,CAACuB,gBAApB,EAAN;AACH;;AACD,WAAOJ,SAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;;;AACoB,QAAVK,UAAU,CAACd,UAAD,EAAaC,OAAb,EAAsB;AAClC,UAAMC,WAAW,GAAG,KAAKC,gBAAL,CAAsBH,UAAtB,EAAkCC,OAAlC,CAApB;AACA,QAAIQ,SAAS,GAAG,CAAhB;;AACA,QAAIP,WAAW,CAACG,QAAhB,EAA0B;AACtB,YAAMD,SAAS,GAAGF,WAAW,CAACG,QAAZ,GAAuB,KAAKA,QAA9C;;AACA,UAAID,SAAS,GAAG,CAAhB,EAAmB;AACf,cAAMW,UAAU,GAAG,IAAIC,UAAJ,CAAed,WAAW,CAACM,MAAZ,GAAqBJ,SAApC,CAAnB;AACAK,QAAAA,SAAS,GAAG,MAAM,KAAKK,UAAL,CAAgBC,UAAhB,EAA4B;AAAEH,UAAAA,SAAS,EAAEV,WAAW,CAACU;AAAzB,SAA5B,CAAlB;AACAZ,QAAAA,UAAU,CAACiB,GAAX,CAAeF,UAAU,CAACG,QAAX,CAAoBd,SAApB,CAAf,EAA+CF,WAAW,CAACS,MAA3D;AACA,eAAOF,SAAS,GAAGL,SAAnB;AACH,OALD,MAMK,IAAIA,SAAS,GAAG,CAAhB,EAAmB;AACpB,cAAM,IAAIG,KAAJ,CAAU,gDAAV,CAAN;AACH;AACJ;;AACD,QAAIL,WAAW,CAACM,MAAZ,GAAqB,CAAzB,EAA4B;AACxB,UAAI;AACAC,QAAAA,SAAS,GAAG,MAAM,KAAKb,YAAL,CAAkBuB,IAAlB,CAAuBnB,UAAvB,EAAmCE,WAAW,CAACS,MAA/C,EAAuDT,WAAW,CAACM,MAAnE,CAAlB;AACH,OAFD,CAGA,OAAOY,GAAP,EAAY;AACR,YAAInB,OAAO,IAAIA,OAAO,CAACW,SAAnB,IAAgCQ,GAAG,YAAY9B,eAAe,CAACuB,gBAAnE,EAAqF;AACjF,iBAAO,CAAP;AACH;;AACD,cAAMO,GAAN;AACH;;AACD,UAAK,CAAClB,WAAW,CAACU,SAAd,IAA4BH,SAAS,GAAGP,WAAW,CAACM,MAAxD,EAAgE;AAC5D,cAAM,IAAIlB,eAAe,CAACuB,gBAApB,EAAN;AACH;AACJ;;AACD,WAAOJ,SAAP;AACH;;AACW,QAANH,MAAM,CAACE,MAAD,EAAS;AACjB;AACA,UAAMa,OAAO,GAAGC,IAAI,CAACC,GAAL,CAAShC,aAAT,EAAwBiB,MAAxB,CAAhB;AACA,UAAMgB,GAAG,GAAG,IAAIR,UAAJ,CAAeK,OAAf,CAAZ;AACA,QAAII,YAAY,GAAG,CAAnB;;AACA,WAAOA,YAAY,GAAGjB,MAAtB,EAA8B;AAC1B,YAAMkB,SAAS,GAAGlB,MAAM,GAAGiB,YAA3B;AACA,YAAMhB,SAAS,GAAG,MAAM,KAAKV,UAAL,CAAgByB,GAAhB,EAAqB;AAAEhB,QAAAA,MAAM,EAAEc,IAAI,CAACC,GAAL,CAASF,OAAT,EAAkBK,SAAlB;AAAV,OAArB,CAAxB;;AACA,UAAIjB,SAAS,GAAG,CAAhB,EAAmB;AACf,eAAOA,SAAP;AACH;;AACDgB,MAAAA,YAAY,IAAIhB,SAAhB;AACH;;AACD,WAAOgB,YAAP;AACH;;AAzFmE;;AA2FxExC,OAAO,CAACE,mBAAR,GAA8BA,mBAA9B","sourcesContent":["\"use strict\";\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nexports.ReadStreamTokenizer = void 0;\r\nconst AbstractTokenizer_1 = require(\"./AbstractTokenizer\");\r\nconst peek_readable_1 = require(\"peek-readable\");\r\nconst maxBufferSize = 256000;\r\nclass ReadStreamTokenizer extends AbstractTokenizer_1.AbstractTokenizer {\r\n    constructor(stream, fileInfo) {\r\n        super(fileInfo);\r\n        this.streamReader = new peek_readable_1.StreamReader(stream);\r\n    }\r\n    /**\r\n     * Get file information, an HTTP-client may implement this doing a HEAD request\r\n     * @return Promise with file information\r\n     */\r\n    async getFileInfo() {\r\n        return this.fileInfo;\r\n    }\r\n    /**\r\n     * Read buffer from tokenizer\r\n     * @param uint8Array - Target Uint8Array to fill with data read from the tokenizer-stream\r\n     * @param options - Read behaviour options\r\n     * @returns Promise with number of bytes read\r\n     */\r\n    async readBuffer(uint8Array, options) {\r\n        const normOptions = this.normalizeOptions(uint8Array, options);\r\n        const skipBytes = normOptions.position - this.position;\r\n        if (skipBytes > 0) {\r\n            await this.ignore(skipBytes);\r\n            return this.readBuffer(uint8Array, options);\r\n        }\r\n        else if (skipBytes < 0) {\r\n            throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\r\n        }\r\n        if (normOptions.length === 0) {\r\n            return 0;\r\n        }\r\n        const bytesRead = await this.streamReader.read(uint8Array, normOptions.offset, normOptions.length);\r\n        this.position += bytesRead;\r\n        if ((!options || !options.mayBeLess) && bytesRead < normOptions.length) {\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        }\r\n        return bytesRead;\r\n    }\r\n    /**\r\n     * Peek (read ahead) buffer from tokenizer\r\n     * @param uint8Array - Uint8Array (or Buffer) to write data to\r\n     * @param options - Read behaviour options\r\n     * @returns Promise with number of bytes peeked\r\n     */\r\n    async peekBuffer(uint8Array, options) {\r\n        const normOptions = this.normalizeOptions(uint8Array, options);\r\n        let bytesRead = 0;\r\n        if (normOptions.position) {\r\n            const skipBytes = normOptions.position - this.position;\r\n            if (skipBytes > 0) {\r\n                const skipBuffer = new Uint8Array(normOptions.length + skipBytes);\r\n                bytesRead = await this.peekBuffer(skipBuffer, { mayBeLess: normOptions.mayBeLess });\r\n                uint8Array.set(skipBuffer.subarray(skipBytes), normOptions.offset);\r\n                return bytesRead - skipBytes;\r\n            }\r\n            else if (skipBytes < 0) {\r\n                throw new Error('Cannot peek from a negative offset in a stream');\r\n            }\r\n        }\r\n        if (normOptions.length > 0) {\r\n            try {\r\n                bytesRead = await this.streamReader.peek(uint8Array, normOptions.offset, normOptions.length);\r\n            }\r\n            catch (err) {\r\n                if (options && options.mayBeLess && err instanceof peek_readable_1.EndOfStreamError) {\r\n                    return 0;\r\n                }\r\n                throw err;\r\n            }\r\n            if ((!normOptions.mayBeLess) && bytesRead < normOptions.length) {\r\n                throw new peek_readable_1.EndOfStreamError();\r\n            }\r\n        }\r\n        return bytesRead;\r\n    }\r\n    async ignore(length) {\r\n        // debug(`ignore ${this.position}...${this.position + length - 1}`);\r\n        const bufSize = Math.min(maxBufferSize, length);\r\n        const buf = new Uint8Array(bufSize);\r\n        let totBytesRead = 0;\r\n        while (totBytesRead < length) {\r\n            const remaining = length - totBytesRead;\r\n            const bytesRead = await this.readBuffer(buf, { length: Math.min(bufSize, remaining) });\r\n            if (bytesRead < 0) {\r\n                return bytesRead;\r\n            }\r\n            totBytesRead += bytesRead;\r\n        }\r\n        return totBytesRead;\r\n    }\r\n}\r\nexports.ReadStreamTokenizer = ReadStreamTokenizer;\r\n"]},"metadata":{},"sourceType":"script"}