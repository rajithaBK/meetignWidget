{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.fromFile = exports.FileTokenizer = void 0;\n\nconst AbstractTokenizer_1 = require(\"./AbstractTokenizer\");\n\nconst peek_readable_1 = require(\"peek-readable\");\n\nconst fs = require(\"./FsPromise\");\n\nclass FileTokenizer extends AbstractTokenizer_1.AbstractTokenizer {\n  constructor(fd, fileInfo) {\n    super(fileInfo);\n    this.fd = fd;\n  }\n  /**\r\n   * Read buffer from file\r\n   * @param uint8Array - Uint8Array to write result to\r\n   * @param options - Read behaviour options\r\n   * @returns Promise number of bytes read\r\n   */\n\n\n  async readBuffer(uint8Array, options) {\n    const normOptions = this.normalizeOptions(uint8Array, options);\n    this.position = normOptions.position;\n    const res = await fs.read(this.fd, uint8Array, normOptions.offset, normOptions.length, normOptions.position);\n    this.position += res.bytesRead;\n\n    if (res.bytesRead < normOptions.length && (!options || !options.mayBeLess)) {\n      throw new peek_readable_1.EndOfStreamError();\n    }\n\n    return res.bytesRead;\n  }\n  /**\r\n   * Peek buffer from file\r\n   * @param uint8Array - Uint8Array (or Buffer) to write data to\r\n   * @param options - Read behaviour options\r\n   * @returns Promise number of bytes read\r\n   */\n\n\n  async peekBuffer(uint8Array, options) {\n    const normOptions = this.normalizeOptions(uint8Array, options);\n    const res = await fs.read(this.fd, uint8Array, normOptions.offset, normOptions.length, normOptions.position);\n\n    if (!normOptions.mayBeLess && res.bytesRead < normOptions.length) {\n      throw new peek_readable_1.EndOfStreamError();\n    }\n\n    return res.bytesRead;\n  }\n\n  async close() {\n    return fs.close(this.fd);\n  }\n\n}\n\nexports.FileTokenizer = FileTokenizer;\n\nasync function fromFile(sourceFilePath) {\n  const stat = await fs.stat(sourceFilePath);\n\n  if (!stat.isFile) {\n    throw new Error(`File not a file: ${sourceFilePath}`);\n  }\n\n  const fd = await fs.open(sourceFilePath, 'r');\n  return new FileTokenizer(fd, {\n    path: sourceFilePath,\n    size: stat.size\n  });\n}\n\nexports.fromFile = fromFile;","map":{"version":3,"sources":["C:/Users/rkanthet/Documents/test_window_object/node_modules/strtok3/lib/FileTokenizer.js"],"names":["Object","defineProperty","exports","value","fromFile","FileTokenizer","AbstractTokenizer_1","require","peek_readable_1","fs","AbstractTokenizer","constructor","fd","fileInfo","readBuffer","uint8Array","options","normOptions","normalizeOptions","position","res","read","offset","length","bytesRead","mayBeLess","EndOfStreamError","peekBuffer","close","sourceFilePath","stat","isFile","Error","open","path","size"],"mappings":"AAAA;;AACAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C;AACAD,OAAO,CAACE,QAAR,GAAmBF,OAAO,CAACG,aAAR,GAAwB,KAAK,CAAhD;;AACA,MAAMC,mBAAmB,GAAGC,OAAO,CAAC,qBAAD,CAAnC;;AACA,MAAMC,eAAe,GAAGD,OAAO,CAAC,eAAD,CAA/B;;AACA,MAAME,EAAE,GAAGF,OAAO,CAAC,aAAD,CAAlB;;AACA,MAAMF,aAAN,SAA4BC,mBAAmB,CAACI,iBAAhD,CAAkE;AAC9DC,EAAAA,WAAW,CAACC,EAAD,EAAKC,QAAL,EAAe;AACtB,UAAMA,QAAN;AACA,SAAKD,EAAL,GAAUA,EAAV;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;;;AACoB,QAAVE,UAAU,CAACC,UAAD,EAAaC,OAAb,EAAsB;AAClC,UAAMC,WAAW,GAAG,KAAKC,gBAAL,CAAsBH,UAAtB,EAAkCC,OAAlC,CAApB;AACA,SAAKG,QAAL,GAAgBF,WAAW,CAACE,QAA5B;AACA,UAAMC,GAAG,GAAG,MAAMX,EAAE,CAACY,IAAH,CAAQ,KAAKT,EAAb,EAAiBG,UAAjB,EAA6BE,WAAW,CAACK,MAAzC,EAAiDL,WAAW,CAACM,MAA7D,EAAqEN,WAAW,CAACE,QAAjF,CAAlB;AACA,SAAKA,QAAL,IAAiBC,GAAG,CAACI,SAArB;;AACA,QAAIJ,GAAG,CAACI,SAAJ,GAAgBP,WAAW,CAACM,MAA5B,KAAuC,CAACP,OAAD,IAAY,CAACA,OAAO,CAACS,SAA5D,CAAJ,EAA4E;AACxE,YAAM,IAAIjB,eAAe,CAACkB,gBAApB,EAAN;AACH;;AACD,WAAON,GAAG,CAACI,SAAX;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;;;AACoB,QAAVG,UAAU,CAACZ,UAAD,EAAaC,OAAb,EAAsB;AAClC,UAAMC,WAAW,GAAG,KAAKC,gBAAL,CAAsBH,UAAtB,EAAkCC,OAAlC,CAApB;AACA,UAAMI,GAAG,GAAG,MAAMX,EAAE,CAACY,IAAH,CAAQ,KAAKT,EAAb,EAAiBG,UAAjB,EAA6BE,WAAW,CAACK,MAAzC,EAAiDL,WAAW,CAACM,MAA7D,EAAqEN,WAAW,CAACE,QAAjF,CAAlB;;AACA,QAAK,CAACF,WAAW,CAACQ,SAAd,IAA4BL,GAAG,CAACI,SAAJ,GAAgBP,WAAW,CAACM,MAA5D,EAAoE;AAChE,YAAM,IAAIf,eAAe,CAACkB,gBAApB,EAAN;AACH;;AACD,WAAON,GAAG,CAACI,SAAX;AACH;;AACU,QAALI,KAAK,GAAG;AACV,WAAOnB,EAAE,CAACmB,KAAH,CAAS,KAAKhB,EAAd,CAAP;AACH;;AArC6D;;AAuClEV,OAAO,CAACG,aAAR,GAAwBA,aAAxB;;AACA,eAAeD,QAAf,CAAwByB,cAAxB,EAAwC;AACpC,QAAMC,IAAI,GAAG,MAAMrB,EAAE,CAACqB,IAAH,CAAQD,cAAR,CAAnB;;AACA,MAAI,CAACC,IAAI,CAACC,MAAV,EAAkB;AACd,UAAM,IAAIC,KAAJ,CAAW,oBAAmBH,cAAe,EAA7C,CAAN;AACH;;AACD,QAAMjB,EAAE,GAAG,MAAMH,EAAE,CAACwB,IAAH,CAAQJ,cAAR,EAAwB,GAAxB,CAAjB;AACA,SAAO,IAAIxB,aAAJ,CAAkBO,EAAlB,EAAsB;AAAEsB,IAAAA,IAAI,EAAEL,cAAR;AAAwBM,IAAAA,IAAI,EAAEL,IAAI,CAACK;AAAnC,GAAtB,CAAP;AACH;;AACDjC,OAAO,CAACE,QAAR,GAAmBA,QAAnB","sourcesContent":["\"use strict\";\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nexports.fromFile = exports.FileTokenizer = void 0;\r\nconst AbstractTokenizer_1 = require(\"./AbstractTokenizer\");\r\nconst peek_readable_1 = require(\"peek-readable\");\r\nconst fs = require(\"./FsPromise\");\r\nclass FileTokenizer extends AbstractTokenizer_1.AbstractTokenizer {\r\n    constructor(fd, fileInfo) {\r\n        super(fileInfo);\r\n        this.fd = fd;\r\n    }\r\n    /**\r\n     * Read buffer from file\r\n     * @param uint8Array - Uint8Array to write result to\r\n     * @param options - Read behaviour options\r\n     * @returns Promise number of bytes read\r\n     */\r\n    async readBuffer(uint8Array, options) {\r\n        const normOptions = this.normalizeOptions(uint8Array, options);\r\n        this.position = normOptions.position;\r\n        const res = await fs.read(this.fd, uint8Array, normOptions.offset, normOptions.length, normOptions.position);\r\n        this.position += res.bytesRead;\r\n        if (res.bytesRead < normOptions.length && (!options || !options.mayBeLess)) {\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        }\r\n        return res.bytesRead;\r\n    }\r\n    /**\r\n     * Peek buffer from file\r\n     * @param uint8Array - Uint8Array (or Buffer) to write data to\r\n     * @param options - Read behaviour options\r\n     * @returns Promise number of bytes read\r\n     */\r\n    async peekBuffer(uint8Array, options) {\r\n        const normOptions = this.normalizeOptions(uint8Array, options);\r\n        const res = await fs.read(this.fd, uint8Array, normOptions.offset, normOptions.length, normOptions.position);\r\n        if ((!normOptions.mayBeLess) && res.bytesRead < normOptions.length) {\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        }\r\n        return res.bytesRead;\r\n    }\r\n    async close() {\r\n        return fs.close(this.fd);\r\n    }\r\n}\r\nexports.FileTokenizer = FileTokenizer;\r\nasync function fromFile(sourceFilePath) {\r\n    const stat = await fs.stat(sourceFilePath);\r\n    if (!stat.isFile) {\r\n        throw new Error(`File not a file: ${sourceFilePath}`);\r\n    }\r\n    const fd = await fs.open(sourceFilePath, 'r');\r\n    return new FileTokenizer(fd, { path: sourceFilePath, size: stat.size });\r\n}\r\nexports.fromFile = fromFile;\r\n"]},"metadata":{},"sourceType":"script"}